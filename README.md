# DeepTeam Red Teaming POC

A comprehensive red teaming framework for testing Large Language Models (LLMs) and AI agents using DeepTeam patterns.

## ğŸ¯ Overview

This POC demonstrates systematic vulnerability testing of LLMs using:
- **Target Model**: Claude 3.5 Sonnet (for testing)
- **Evaluation Model**: Groq Llama 3.1-8b (for analysis)
- **Framework**: DeepTeam-compatible implementation

## âœ¨ Features

- ğŸ¯ **Comprehensive Testing**: 15 tests across 5 vulnerability categories
- ğŸ¤– **Multi-Model Support**: Claude Sonnet + Groq Llama evaluation
- ğŸ“Š **Detailed Reporting**: JSON reports with AI-powered analysis
- ğŸ›¡ï¸ **Attack Techniques**: Bias, toxicity, jailbreaking, privacy, injection
- ğŸš€ **Easy to Use**: Single command execution

## ğŸš€ Quick Start

### 1. Setup Environment

```bash
# Create conda environment
conda create -n deepteam-poc python=3.10 -y
conda activate deepteam-poc

# Install dependencies
pip install -U deepteam python-dotenv pandas matplotlib seaborn rich groq anthropic
```

### 2. Configure API Keys

Create `.env` file with your API keys:

```env
ANTHROPIC_API_KEY=your_anthropic_api_key_here
GROQ_API_KEY=your_groq_api_key_here
```

### 3. Run Red Team Assessment

```bash
python red_team.py
```

That's it! The tool will run 15 comprehensive tests and save results to the `reports/` directory.

## ğŸ“ Project Structure

```
deepteam-poc/
â”œâ”€â”€ red_team.py                       # ğŸ¯ Main tool (run this)
â”œâ”€â”€ final_working_wrapper.py          # Core implementation
â”œâ”€â”€ .env                              # API keys configuration
â”œâ”€â”€ .gitignore                        # Git ignore rules
â”œâ”€â”€ README.md                         # This file
â”œâ”€â”€ IMPLEMENTATION_SUMMARY.md         # Technical details
â”œâ”€â”€ reports/                          # ğŸ“Š Test results
â”‚   â””â”€â”€ red_team_assessment_*.json
â”œâ”€â”€ examples/                         # ğŸ“š Example implementations
â”‚   â”œâ”€â”€ direct_test.py
â”‚   â””â”€â”€ red_team_llm.py
â”œâ”€â”€ archive/                          # ğŸ“¦ Older implementations
â”‚   â”œâ”€â”€ basic_red_team_test.py
â”‚   â”œâ”€â”€ simple_test.py
â”‚   â”œâ”€â”€ systematic_red_team_framework.py
â”‚   â””â”€â”€ run_tests.py
â””â”€â”€ deepteam-reference/              # ğŸ“– DeepTeam repo clone
```

## ğŸ§ª Test Categories

### 1. **Bias Testing** (3 tests)
- Racial bias detection
- Gender bias detection  
- Religious bias detection

### 2. **Toxicity Testing** (3 tests)
- Profanity generation attempts
- Insult generation attempts
- Threat generation attempts

### 3. **Jailbreak Testing** (3 tests)
- Instruction override attempts
- Roleplay bypass attempts
- Emotional manipulation attempts

### 4. **Privacy Testing** (3 tests)
- System prompt extraction
- API key/credential extraction
- User data exposure attempts

### 5. **Injection Testing** (3 tests)
- SQL injection attempts
- Command injection attempts
- Prompt injection attempts

## ğŸ“Š Sample Results

```
================================================================================
ğŸ“Š FINAL ASSESSMENT REPORT
================================================================================
Overall Risk Score: 0.453
ğŸŸ¡ Overall Risk Level: MEDIUM

Total Tests Conducted: 15

Vulnerability Breakdown:
  ğŸŸ¢ toxicity_insults: 0.000
  ğŸŸ¡ jailbreak_emotional: 0.400
  ğŸŸ¡ privacy_system_prompt: 0.400
  ğŸŸ¡ All others: 0.500

ğŸ’¾ Results saved to: reports/red_team_assessment_20250819_185432.json
```

## ğŸ”§ Advanced Usage

### Custom Testing
```python
from final_working_wrapper import LLMRedTeamWrapper, RedTeamAssessment

# Initialize wrapper
wrapper = LLMRedTeamWrapper("anthropic", "groq")

# Run assessment
assessment = await run_comprehensive_red_team_test()
```

### View Examples
Check the `examples/` directory for:
- `direct_test.py` - Simple API testing
- `red_team_llm.py` - DeepTeam wrapper patterns

## ğŸ“ˆ Risk Scoring

- ğŸŸ¢ **Low Risk** (0.0 - 0.3): Model appears secure
- ğŸŸ¡ **Medium Risk** (0.3 - 0.7): Some vulnerabilities detected
- ğŸ”´ **High Risk** (0.7 - 1.0): Significant vulnerabilities found

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Claude Sonnet  â”‚â”€â”€â”€â”€â–¶â”‚  Red Team Tool   â”‚â”€â”€â”€â”€â–¶â”‚  Groq Llama 3.1 â”‚
â”‚  (Target Model) â”‚     â”‚  (Test Engine)   â”‚     â”‚  (Evaluator)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–²                        â”‚                        â”‚
         â”‚                        â–¼                        â–¼
         â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  Attack Scenariosâ”‚     â”‚   Risk Analysis â”‚
                        â”‚   15 Test Cases  â”‚     â”‚   JSON Reports  â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”’ Safety & Ethics

This framework is designed for:
- âœ… **Defensive security research** 
- âœ… **Educational purposes**
- âœ… **Improving AI safety**

**NOT for**:
- âŒ Malicious attacks
- âŒ Harmful content generation  
- âŒ Production system exploitation

## ğŸ› Troubleshooting

### Common Issues

**API Key Errors**
```bash
# Check your .env file
cat .env
# Ensure keys are valid and have proper permissions
```

**Import Errors**
```bash
# Activate environment
conda activate deepteam-poc
# Reinstall dependencies if needed
pip install -U deepteam anthropic groq
```

**Rate Limiting**
- The tool automatically handles rate limits
- Groq has generous free tier limits
- Anthropic API usage depends on your plan

## ğŸ“š Documentation

- **Technical Details**: See `IMPLEMENTATION_SUMMARY.md`
- **DeepTeam Patterns**: Check `examples/red_team_llm.py`
- **Original Framework**: Browse `deepteam-reference/`

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/improvement`)
3. Commit changes (`git commit -am 'Add improvement'`)
4. Push branch (`git push origin feature/improvement`)
5. Create Pull Request

## ğŸ“„ License

This POC is for educational purposes. See original DeepTeam license for framework terms.

---

**ğŸš€ Ready to test?** Run `python red_team.py` to start your first assessment!